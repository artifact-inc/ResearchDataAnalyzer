{"id": "rdla_20251118_000603", "tier": "B", "data_type_name": "Frequency Estimation Dataset", "value_score": 7.299999999999999, "confidence_score": 9.0, "dataset_description": "The research does not appear to use a specific dataset, but rather focuses on developing a new frequency estimation algorithm using a Residue Number System (RNS) and differential privacy techniques.", "data_collection_method": "Not applicable, as the research does not use a specific dataset.", "replication_feasibility": "High, as the proposed algorithm can be implemented and tested using publicly available tools and libraries. However, the feasibility of applying the technique to real-world datasets may depend on the specific data sources and regulatory requirements.", "paper_url": "https://arxiv.org/abs/2511.11569v1", "paper_title": "Private Frequency Estimation Via Residue Number Systems", "detected_at": "2025-11-18T00:06:03.154088+00:00"}
{"id": "rdla_20251118_000618", "tier": "B", "data_type_name": "Object hallucination detection", "value_score": 6.8, "confidence_score": 7.0, "dataset_description": "The paper uses synthetic datasets to evaluate the PAS method, including the Hallucinated Objects in VQA (HOV) and the Visual Madlibs (VML) datasets.", "data_collection_method": "The synthetic datasets were generated by introducing object hallucinations into existing vision-language datasets.", "replication_feasibility": "medium. While the synthetic datasets used in the paper are accessible, replicating the object hallucination patterns in real-world datasets would require significant effort and access to proprietary model training data.", "paper_url": "https://arxiv.org/abs/2511.11502v1", "paper_title": "PAS : Prelim Attention Score for Detecting Object Hallucinations in Large Vision--Language Models", "detected_at": "2025-11-18T00:06:18.181943+00:00"}
{"id": "rdla_20251118_000654", "tier": "B", "data_type_name": "Digitized histopathology slides", "value_score": 6.8, "confidence_score": 7.0, "dataset_description": "The paper mentions the use of a 90-question benchmark dataset called SlideQuest, which was verified by pathologists and biomedical scientists. However, the specific details of the histopathology slides used in this dataset are not provided.", "data_collection_method": "The paper does not provide details on how the SlideQuest dataset was obtained or curated. It is unclear if the slides were manually annotated by experts, collected from existing sources, or generated synthetically.", "replication_feasibility": "medium - Obtaining a comprehensive dataset of digitized histopathology slides may require partnerships with medical institutions and careful consideration of privacy and regulatory concerns. The process of curating a benchmark dataset like SlideQuest would also require significant effort and domain expertise.", "paper_url": "https://arxiv.org/abs/2511.11324v1", "paper_title": "NOVA: An Agentic Framework for Automated Histopathology Analysis and Discovery", "detected_at": "2025-11-18T00:06:54.541364+00:00"}
{"id": "rdla_20251118_000658", "tier": "B", "data_type_name": "Simulated social navigation data", "value_score": 6.449999999999999, "confidence_score": 9.0, "dataset_description": "The paper used simulated data from a rule-based social locomotion model to train the reinforcement learning framework. The specific details of the dataset are not provided.", "data_collection_method": "The data was generated through simulations based on a rule-based social locomotion model, which was grounded in empirical behavioral experiments.", "replication_feasibility": "medium. Replicating the dataset would require access to the specific simulation environment and implementation of the rule-based social locomotion model, which may not be easily accessible. Additionally, the paper does not provide detailed information on the dataset, making it challenging to reproduce the experiments.", "paper_url": "https://arxiv.org/abs/2511.11323v1", "paper_title": "RLSLM: A Hybrid Reinforcement Learning Framework Aligning Rule-Based Social Locomotion Model with Human Social Norms", "detected_at": "2025-11-18T00:06:58.222367+00:00"}
{"id": "rdla_20251118_000701", "tier": "A", "data_type_name": "Financial language models", "value_score": 7.85, "confidence_score": 7.0, "dataset_description": "The paper does not provide specific details on the datasets used for training and evaluation. It mentions the use of the FLARE and FLARE-ES benchmarks, which are financial NLP datasets, as well as unnamed 'financial NLP tasks'.", "data_collection_method": "The data collection method is not explicitly described in the paper. It's likely that the FLARE and FLARE-ES benchmarks were obtained through web scraping or partnerships with financial institutions, but the details are unclear.", "replication_feasibility": "Medium. The use of financial NLP benchmarks suggests the data may not be publicly available, requiring partnerships or moderate effort to obtain. The lack of specific details on the datasets used makes it difficult to assess the feasibility of replication.", "paper_url": "https://arxiv.org/abs/2511.11315v1", "paper_title": "LAET: A Layer-wise Adaptive Ensemble Tuning Framework for Pretrained Language Models", "detected_at": "2025-11-18T00:07:01.525623+00:00"}
{"id": "rdla_20251118_000716", "tier": "B", "data_type_name": "Visual Concept Unlearning Benchmark (VCUBench)", "value_score": 7.299999999999999, "confidence_score": 9.0, "dataset_description": "VCUBench, a benchmark dataset constructed by the authors to evaluate visual concept unlearning, containing both synthetic and real-world visual data", "data_collection_method": "A combination of synthetic data generation and web scraping of real-world visual content", "replication_feasibility": "Medium. Constructing a comprehensive visual benchmark dataset requires significant effort, though the authors' approach provides a starting point. Obtaining permissions for web-scraped real-world data may also present challenges.", "paper_url": "https://arxiv.org/abs/2511.11299v1", "paper_title": "AUVIC: Adversarial Unlearning of Visual Concepts for Multi-modal Large Language Models", "detected_at": "2025-11-18T00:07:16.032746+00:00"}
{"id": "rdla_20251118_000735", "tier": "B", "data_type_name": "Software Quality Dataset (SQuaD)", "value_score": 6.1, "confidence_score": 9.0, "dataset_description": "The SQuaD dataset includes over 700 unique software quality metrics extracted from 450 mature open-source projects across various ecosystems, including Apache, Mozilla, FFmpeg, and the Linux kernel. The dataset covers a total of 63,586 analyzed project releases.", "data_collection_method": "The researchers integrated nine state-of-the-art static analysis tools to extract the software quality metrics, including SonarQube, CodeScene, PMD, Understand, CK, JaSoMe, RefactoringMiner, RefactoringMiner++, and PyRef.", "replication_feasibility": "Medium. While the open-source projects and analysis tools used are publicly available, the specific data collection and integration process may require significant effort to replicate, especially for researchers without prior experience with these tools and ecosystems.", "paper_url": "https://arxiv.org/abs/2511.11265v1", "paper_title": "SQuaD: The Software Quality Dataset", "detected_at": "2025-11-18T00:07:35.704177+00:00"}
{"id": "rdla_20251118_000739", "tier": "B", "data_type_name": "Ionic Liquid Dataset", "value_score": 6.449999999999999, "confidence_score": 7.0, "dataset_description": "The researchers curated a new, comprehensive dataset of ionic liquids and their properties, including both experimental and computational data. The dataset covers a wide range of structural variations and property measurements.", "data_collection_method": "The dataset was compiled from various literature sources, including published research papers and online databases. The researchers also performed computational simulations to generate additional property data.", "replication_feasibility": "Medium. While the dataset is not publicly available, the researchers indicate that it can be replicated through a combination of literature mining and computational modeling. However, this may require significant effort and specialized expertise.", "paper_url": "https://arxiv.org/abs/2511.11257v1", "paper_title": "AIonopedia: an LLM agent orchestrating multimodal learning for ionic liquid discovery", "detected_at": "2025-11-18T00:07:39.823205+00:00"}
{"id": "rdla_20251118_000743", "tier": "B", "data_type_name": "UAV Flight Scenario Benchmark", "value_score": 6.449999999999999, "confidence_score": 9.0, "dataset_description": "The UAVBench dataset comprises 50,000 validated UAV flight scenarios generated through taxonomy-guided LLM prompting and multi-stage safety validation. Each scenario is encoded in a structured JSON schema that includes mission objectives, vehicle configuration, environmental conditions, and quantitative risk labels.", "data_collection_method": "The flight scenarios were generated using large language models (LLMs) and then validated through a multi-stage process to ensure their safety and realism.", "replication_feasibility": "Medium. While the data collection process is not fully described, the use of LLMs and a validation pipeline suggests that replicating the dataset may require significant technical expertise and resources. Partnerships with the research team or access to similar LLM capabilities would likely be necessary.", "paper_url": "https://arxiv.org/abs/2511.11252v1", "paper_title": "UAVBench: An Open Benchmark Dataset for Autonomous and Agentic AI UAV Systems via LLM-Generated Flight Scenarios", "detected_at": "2025-11-18T00:07:43.994992+00:00"}
{"id": "rdla_20251118_000822", "tier": "B", "data_type_name": "VideoP2R-CoT-162K", "value_score": 6.1, "confidence_score": 9.0, "dataset_description": "The VideoP2R-CoT-162K dataset contains 162,000 video clips with associated chain-of-thought annotations that capture the distinction between perception and reasoning.", "data_collection_method": "The dataset was generated using a synthetic video generation process and crowdsourced annotations.", "replication_feasibility": "Medium. While the data generation process is described, replicating the full dataset at scale would require significant effort and coordination with the authors. The lack of real-world data sources may also limit the dataset's broader applicability.", "paper_url": "https://arxiv.org/abs/2511.11113v1", "paper_title": "VIDEOP2R: Video Understanding from Perception to Reasoning", "detected_at": "2025-11-18T00:08:22.494501+00:00"}
{"id": "rdla_20251118_000826", "tier": "B", "data_type_name": "Planning problem datasets", "value_score": 6.449999999999999, "confidence_score": 9.0, "dataset_description": "The specific datasets used in the experiments are not described in the paper, only referred to as 'various classical and numeric planning domains'.", "data_collection_method": "Unknown, as the paper does not provide details on the data collection process.", "replication_feasibility": "medium. While the paper describes a novel planning algorithm, the lack of information on the specific datasets used makes it difficult to assess the feasibility of replicating the experiments. Obtaining relevant planning problem datasets may require partnerships or custom data collection efforts.", "paper_url": "https://arxiv.org/abs/2511.11095v1", "paper_title": "Satisficing and Optimal Generalised Planning via Goal Regression (Extended Version)", "detected_at": "2025-11-18T00:08:26.324397+00:00"}
{"id": "rdla_20251118_000829", "tier": "B", "data_type_name": "Radiology Image-Report Pairs", "value_score": 6.449999999999999, "confidence_score": 7.0, "dataset_description": "Unspecified size of chest radiograph and corresponding radiology reports, potentially from a single or limited number of healthcare institutions", "data_collection_method": "Not provided, likely a combination of manual annotation and extraction from clinical systems", "replication_feasibility": "medium, requires partnerships with healthcare providers and careful navigation of privacy/regulatory requirements", "paper_url": "https://arxiv.org/abs/2511.11066v1", "paper_title": "S2D-ALIGN: Shallow-to-Deep Auxiliary Learning for Anatomically-Grounded Radiology Report Generation", "detected_at": "2025-11-18T00:08:29.302382+00:00"}
{"id": "rdla_20251118_000838", "tier": "B", "data_type_name": "Multilingual Text Embeddings", "value_score": 6.8, "confidence_score": 9.0, "dataset_description": "The paper uses the Massive Multilingual Text Embedding Benchmark (MMTEB) dataset, which includes text embeddings for 38 different models across various languages and tasks.", "data_collection_method": "The MMTEB dataset is a compilation of existing text embedding models and their performance on various benchmarks. The authors do not describe how the individual text embedding models were obtained or created.", "replication_feasibility": "Medium. The MMTEB dataset is publicly available, but replicating the text embedding models used in the study may require access to the original training data and models, which could be challenging to obtain or recreate. Additionally, the paper does not provide detailed information about the specific text embedding models used, making it difficult to fully replicate the study.", "paper_url": "https://arxiv.org/abs/2511.11041v1", "paper_title": "Correcting Mean Bias in Text Embeddings: A Refined Renormalization with Training-Free Improvements on MMTEB", "detected_at": "2025-11-18T00:08:38.678096+00:00"}
{"id": "rdla_20251118_000846", "tier": "B", "data_type_name": "CrossMed medical multimodal dataset", "value_score": 6.299999999999999, "confidence_score": 7.5, "dataset_description": "CrossMed is a synthetic dataset reformulating 4 existing medical imaging datasets (CheXpert, SIIM-ACR, BraTS 2020, MosMedData) into a unified visual question answering format, resulting in 20,200 multiple-choice QA instances across modalities (X-ray, MRI, CT), anatomies, and task types (classification, segmentation).", "data_collection_method": "Existing public datasets were reformatted into a new VQA format, without any new data collection", "replication_feasibility": "medium - The underlying datasets used to create CrossMed are publicly available, but reformatting them into a unified benchmark would require significant engineering effort and coordination across multiple sources", "paper_url": "https://arxiv.org/abs/2511.11034v1", "paper_title": "CrossMed: A Multimodal Cross-Task Benchmark for Compositional Generalization in Medical Imaging", "detected_at": "2025-11-18T00:08:46.354928+00:00"}
{"id": "rdla_20251118_000849", "tier": "B", "data_type_name": "Chest X-rays with Insurance Type Annotations", "value_score": 6.1, "confidence_score": 9.0, "dataset_description": "The study used the MIMIC-CXR-JPG and CheXpert datasets, containing a total of over 377,000 chest X-ray images with associated metadata including patient health insurance type.", "data_collection_method": "The datasets were collected from electronic health records at academic medical centers, with chest X-rays and insurance information extracted from structured data fields.", "replication_feasibility": "Medium. Obtaining large-scale medical imaging datasets with detailed patient socioeconomic data requires navigating privacy regulations and building partnerships with healthcare providers. The data collection process is not trivial but feasible with sufficient resources and access.", "paper_url": "https://arxiv.org/abs/2511.11030v1", "paper_title": "Algorithms Trained on Normal Chest X-rays Can Predict Health Insurance Types", "detected_at": "2025-11-18T00:08:49.837144+00:00"}
{"id": "rdla_20251118_000853", "tier": "A", "data_type_name": "Multi-drone collaborative perception dataset", "value_score": 7.6, "confidence_score": 7.0, "dataset_description": "The dataset includes over 14.6k questions derived from both simulator and real-world drone footage, covering tasks related to scene understanding, object recognition, perception assessment, and collaborative decision-making.", "data_collection_method": "A combination of simulated drone flights and real-world data collected from drone operations, with human-annotated ground truth.", "replication_feasibility": "Medium - Replicating the real-world drone data collection may require partnerships with drone operators and regulatory approvals, but the simulated data should be more accessible.", "paper_url": "https://arxiv.org/abs/2511.11025v1", "paper_title": "AirCopBench: A Benchmark for Multi-drone Collaborative Embodied Perception and Reasoning", "detected_at": "2025-11-18T00:08:53.625937+00:00"}
{"id": "rdla_20251118_000905", "tier": "B", "data_type_name": "Audio dialogue corpus", "value_score": 6.8, "confidence_score": 9.0, "dataset_description": "The paper used a proprietary dataset called MarketCalls, which contains audio recordings of customer service calls. The dataset size and diversity are not specified.", "data_collection_method": "The data was obtained from an unspecified commercial partner, likely through recordings of customer service interactions.", "replication_feasibility": "Medium. The use of a proprietary dataset makes it difficult to directly replicate the research. Collecting a similar dataset would require partnerships with organizations in the target industries, which could be challenging without clear validation of demand.", "paper_url": "https://arxiv.org/abs/2511.11000v1", "paper_title": "DialogGraph-LLM: Graph-Informed LLMs for End-to-End Audio Dialogue Intent Recognition", "detected_at": "2025-11-18T00:09:05.404585+00:00"}
{"id": "rdla_20251118_000909", "tier": "B", "data_type_name": "Preference Optimization Datasets", "value_score": 6.1499999999999995, "confidence_score": 9.0, "dataset_description": "The paper analyzes several open-source DPO datasets, including TuluDPO, ORPO, UltraFeedback, HelpSteer, and Code-Preference-Pairs, which contain pairs of preferred and less favorable text completions.", "data_collection_method": "The specific data collection methods for these datasets are not clearly described in the paper, but they appear to be curated by the broader LLM community rather than through a standardized process.", "replication_feasibility": "Medium. While the datasets are open-source and publicly available, the lack of clear documentation on the data collection methods and curation processes may make it challenging to replicate the datasets at scale or understand their limitations. Partnerships with the dataset creators or further investigation would be required.", "paper_url": "https://arxiv.org/abs/2511.10985v1", "paper_title": "When Data is the Algorithm: A Systematic Study and Curation of Preference Optimization Datasets", "detected_at": "2025-11-18T00:09:09.901782+00:00"}
{"id": "rdla_20251118_000913", "tier": "B", "data_type_name": "Expert Domain Discourse-Level Translation Corpus", "value_score": 6.1, "confidence_score": 9.0, "dataset_description": "The DiscoX dataset consists of 200 professionally-curated texts from 7 expert domains, with an average length of over 1700 tokens, focused on Chinese-to-English translation.", "data_collection_method": "The texts were professionally selected and curated by domain experts to ensure high-quality, discourse-level content suitable for evaluating translation systems.", "replication_feasibility": "medium. Replicating a similar dataset would require significant effort to secure partnerships with domain experts, obtain permissions, and curate high-quality content at scale. The costs and time involved in this process could be a barrier.", "paper_url": "https://arxiv.org/abs/2511.10984v1", "paper_title": "DiscoX: Benchmarking Discourse-Level Translation task in Expert Domains", "detected_at": "2025-11-18T00:09:13.822650+00:00"}
{"id": "rdla_20251118_000917", "tier": "B", "data_type_name": "Synthetic video data", "value_score": 6.8, "confidence_score": 7.5, "dataset_description": "The research used synthetic video data to evaluate the PAS technique, rather than real-world video datasets.", "data_collection_method": "The video data was synthetically generated, rather than collected from real-world sources.", "replication_feasibility": "Medium. While the synthetic video generation process is described, replicating the exact datasets used in the paper may require significant effort. Obtaining and curating real-world video datasets for further validation would also be a non-trivial task.", "paper_url": "https://arxiv.org/abs/2511.10979v1", "paper_title": "PAS: A Training-Free Stabilizer for Temporal Encoding in Video LLMs", "detected_at": "2025-11-18T00:09:17.706776+00:00"}
{"id": "rdla_20251118_000936", "tier": "B", "data_type_name": "Rare Disease Diagnosis", "value_score": 6.8, "confidence_score": 9.0, "dataset_description": "The dataset consists of 176 symptom-diagnosis pairs extracted from the TV series House M.D., which is validated for teaching rare disease recognition in medical education.", "data_collection_method": "The data was manually extracted from the TV series by the researchers.", "replication_feasibility": "Medium. While the data collection method is straightforward, the limited size and the use of a TV series as the source raises concerns about the feasibility of scaling and replicating the dataset for broader use. Obtaining larger, more representative datasets of real-world rare disease cases would likely require partnerships with healthcare organizations and extensive data curation efforts.", "paper_url": "https://arxiv.org/abs/2511.10912v1", "paper_title": "Evaluating Large Language Models on Rare Disease Diagnosis: A Case Study using House M.D", "detected_at": "2025-11-18T00:09:36.925626+00:00"}
{"id": "rdla_20251118_000949", "tier": "B", "data_type_name": "Satellite imagery for rainfall nowcasting", "value_score": 6.1, "confidence_score": 9.0, "dataset_description": "The research used the Weather4Cast 2025 benchmark dataset, which consists of satellite imagery and associated rainfall accumulation data.", "data_collection_method": "The Weather4Cast 2025 dataset was likely created by aggregating satellite data from various sources and annotating the rainfall accumulation, but the full details are unclear from the paper.", "replication_feasibility": "Medium. Obtaining high-quality satellite imagery and rainfall data at scale would require partnerships with weather agencies and data providers, as well as significant effort to curate and annotate the dataset.", "paper_url": "https://arxiv.org/abs/2511.10894v1", "paper_title": "DINOv3 as a Frozen Encoder for CRPS-Oriented Probabilistic Rainfall Nowcasting", "detected_at": "2025-11-18T00:09:49.242893+00:00"}
